{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "inputs = layers.Input(input_shape)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), # optimization\n",
    "             loss='sparse_categorical_crossentropy', # loss function\n",
    "             metrics=['accuracy']) # metrics / accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preprocess\n",
    "\n",
    "train_paths = sorted(glob('/Users/sengjeawang/Desktop/data/dataset/cifar/train/*.png'))[:100]\n",
    "test_paths = sorted(glob('/Users/sengjeawang/Desktop/data/dataset/cifar/test/*.png'))[:100]\n",
    "\n",
    "len(train_paths), len(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(path):\n",
    "    return path.split('_')[-1].replace('.png', '')\n",
    "\n",
    "train_labels = [get_class_name(path) for path in train_paths]\n",
    "class_names = np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path):\n",
    "    fname = tf.strings.split(path, '_')[-1]\n",
    "    lbl_name = tf.strings.regex_replace(fname, '.png', '')\n",
    "    onehot = tf.cast(lbl_name == class_names, tf.uint8)\n",
    "    return tf.argmax(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_label(path):\n",
    "    gfile = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    \n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    \n",
    "    label = get_label(path)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_dataset = train_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(image_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_paths))\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "test_dataset = test_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sengjeawang/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 1s 131ms/step - loss: 2.3460 - accuracy: 0.1029 - val_loss: 2.3367 - val_accuracy: 0.0417\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 2.3049 - accuracy: 0.0938 - val_loss: 2.3137 - val_accuracy: 0.0729\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2676 - accuracy: 0.1324 - val_loss: 2.3065 - val_accuracy: 0.1771\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 2.3420 - accuracy: 0.0735 - val_loss: 2.3181 - val_accuracy: 0.0729\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 2.3008 - accuracy: 0.1029 - val_loss: 2.3361 - val_accuracy: 0.0729\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "steps_per_epoch = len(train_paths) // batch_size\n",
    "validation_steps = len(test_paths) // batch_size\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=num_epochs,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sengjeawang/Desktop/data/dataset/cifar/test/0_cat.png'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "\n",
    "# 이미지를 load 직접 load 해서 넣는 방법\n",
    "\n",
    "path = test_paths[0]\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfile = tf.io.read_file(path)\n",
    "image = tf.io.decode_image(gfile, dtype=tf.float32)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image[tf.newaxis, ...]  # batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 32, 32, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09360774, 0.08180645, 0.12770115, 0.09362813, 0.10488072,\n",
       "        0.07301791, 0.11304475, 0.08934409, 0.13893044, 0.08403867]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator에서 데이터를 가져오는 방법\n",
    "\n",
    "test_image, test_label = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 32, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09360772, 0.08180644, 0.12770113, 0.09362812, 0.10488072,\n",
       "       0.07301791, 0.11304474, 0.08934409, 0.13893044, 0.08403865],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image, label in test_dataset.take(1):\n",
    "    plt.imshow(image[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator에 넣는 방법\n",
    "\n",
    "pred = model.predict_generator(test_dataset.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 32, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 2.3516 - accuracy: 0.1250\n"
     ]
    }
   ],
   "source": [
    "evals = model.evaluate(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.351576566696167, 0.125]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
