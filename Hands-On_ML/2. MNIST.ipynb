{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMpblyemAfA+Z7mtmKZcdct"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "APEBDdL3Oovw"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import fetch_openml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IleGOm3LQH6B"
      },
      "source": [
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "mnist.keys()\n",
        "# DESCR: 데이터셋 설명\n",
        "# data: 샘플이 하나의 행, 특성이 하나의 열로 구성된 배열\n",
        "# target: 레이블 배열"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngu-i27FQqtm"
      },
      "source": [
        "X, y = mnist['data'], mnist['target']\n",
        "X.shape, y.shape\n",
        "# 28x28 = 784개의 feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GkImTBY9UT8"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "some_digit = X[0]\n",
        "some_digit_image = some_digit.reshape(28, 28)\n",
        "\n",
        "plt.imshow(some_digit_image, cmap='binary')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jwxJJK09WaP"
      },
      "source": [
        "y[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPtmQKHnAtNf"
      },
      "source": [
        "# label이 문자열이다. 대부분 머신러닝 알고리즘은 숫자를 기대하므로 y를 정수로 변환.\n",
        "y = y.astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEPdVsXtBIEZ"
      },
      "source": [
        "# MNIST의 훈련 세트는 이미 섞여 있어서 모든 교차 검증 폴드를 비슷하게 만듬.\n",
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnZPVjnTBVgy"
      },
      "source": [
        "# 5만을 식별하는 이진 분류기\n",
        "y_train_5 = (y_train == 5)\n",
        "y_test_5 = (y_test == 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWqd5DvqCQVa"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "# 확률적 경사 하강법 (Stochastic GD)\n",
        "\n",
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "sgd_clf.fit(X_train, y_train_5)\n",
        "sgd_clf.predict([some_digit])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzNzLJwoEK1N"
      },
      "source": [
        "# cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.base import clone\n",
        "\n",
        "skfolds = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
        "\n",
        "# 3 fold\n",
        "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
        "    clone_clf = clone(sgd_clf)\n",
        "    X_train_folds = X_train[train_index]\n",
        "    y_train_folds = y_train_5[train_index]\n",
        "    X_test_fold = X_train[test_index]\n",
        "    y_test_fold = y_train_5[test_index]\n",
        "\n",
        "    clone_clf.fit(X_train_folds, y_train_folds)\n",
        "    y_pred = clone_clf.predict(X_test_fold)\n",
        "    n_correct = sum(y_pred == y_test_fold)\n",
        "    print(n_correct / len(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9ndmoKxHXGb"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSh0vRXSLCgB"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class Never5Classifier(BaseEstimator):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return np.zeros((len(X), 1), dtype=bool)\n",
        "\n",
        "never_5_clf = Never5Classifier()\n",
        "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring='accuracy')\n",
        "\n",
        "# 모든 이미지를 '5 아님'으로 분류했을때 정확도 90% 나옴\n",
        "# accuracy를 성능 측정 지표로 선호하지 않는 이유\n",
        "# 불균형한 데이터셋(어떤 클래스가 다른 것보다 월등히 많은 겅우)을 다룰때 더욱 심하다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m22J_9sLetW"
      },
      "source": [
        "# 오차 행렬 (confusion matrix)\n",
        "# 클래스 A를 클래스 B로 잘못 분류된 횟수를 세는 것.\n",
        "# 분류기가 숫자 5의 이미지를 3으로 잘못 분류한 횟수 -> 오차 행렬의 5행 3열\n",
        "\n",
        "# 먼저 실제 타깃과 비교를 위한 예측값 생성\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
        "\n",
        "# 오차 행렬 생성\n",
        "# 행=실제 클래스, 열=예측한 클래스\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_train_5, y_train_pred)\n",
        "# 첫번째 행 '5 아님' 이미지를 '5 아님'으로 정확히 분류: 53057개, 나머지 1522개는 '5'라고 잘못 분류\n",
        "# 두번째 행 '5' 이미지를 '5 아님'으로 잘못 분류: 1325개, 나머지 4096개는 정확히 '5'라고 분류\n",
        "#                    예측\n",
        "#               음성        양성\n",
        "#       음성   53892        687\n",
        "# 실제                             ㅅ\n",
        "#       양성   1891         3530   | 정밀도\n",
        "#                    <-재현율"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qN92nSzOFU2"
      },
      "source": [
        "# 완벽한 분류기의 경우 진짜 양성과 진짜 음성만 있을 것이므로 오차 행렬의 주대각선만 0이 아님\n",
        "y_train_perfect_predictions = y_train_5\n",
        "confusion_matrix(y_train_5, y_train_perfect_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M01DF9lT15B"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# 정밀도 (precision)\n",
        "print(precision_score(y_train_5, y_train_pred))\n",
        "# 재현율 (recall)\n",
        "print(recall_score(y_train_5, y_train_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcrpHXfrWLsZ"
      },
      "source": [
        "# F1 score = 정밀도와 재현율의 조화 평균(harmonic mean)\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(y_train_5, y_train_pred)\n",
        "# 정밀도를 올리면 재현율이 줄고 그 반대도 마찬가지. 정밀도/재현율 트레이드오프"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FotArymkgc4z"
      },
      "source": [
        "y_score = sgd_clf.decision_function([some_digit])\n",
        "print(y_score)\n",
        "threshold = 0\n",
        "y_some_digit_pred = (y_score > threshold)\n",
        "y_some_digit_pred\n",
        "\n",
        "# SGDClassifier의 임곗값이 0이므로 predict와 같은 결과 반환"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5krTTRQhA7j"
      },
      "source": [
        "threshold = 8000\n",
        "y_some_digit_pred = (y_score > threshold)\n",
        "y_some_digit_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNCaCjDphQaN"
      },
      "source": [
        "# 모든 샘플의 점수를 구함 (예측 결과가 아닌 결정 점수 반환)\n",
        "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5,\n",
        "                            cv=3, method='decision_function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i75B2COlhmke"
      },
      "source": [
        "# 모든 임계값에 대해 정밀도와 재현율을 계산\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
        "\n",
        "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
        "    plt.plot(thresholds, precisions[:-1], 'b--', label='정밀도')\n",
        "    plt.plot(thresholds, recalls[:-1], 'g-', label='재현율')\n",
        "\n",
        "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roGF7d9YiBGf"
      },
      "source": [
        "# argmax는 최댓값의 첫번째 인덱스를 반환. 여기서는 첫번째 True 값을 의미.\n",
        "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n",
        "print(threshold_90_precision)\n",
        "\n",
        "# 임계값 설정 (점수가 3370보다 높은것들)\n",
        "y_train_pred_90 = (y_scores >= threshold_90_precision)\n",
        "print(y_train_pred_90)\n",
        "\n",
        "print(precision_score(y_train_5, y_train_pred_90))\n",
        "print(recall_score(y_train_5, y_train_pred_90))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--bWMnv7Ntok"
      },
      "source": [
        "def plot_precision_vs_recall(precisions, recalls):\n",
        "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
        "    plt.xlabel(\"Recall\", fontsize=16)\n",
        "    plt.ylabel(\"Precision\", fontsize=16)\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.grid(True)\n",
        "\n",
        "plot_precision_vs_recall(precisions, recalls)\n",
        "plt.show()\n",
        "# 곡선이 오른쪽 위에 가까워질수록 좋음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnZlswACEn2k"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# fpr = 1 - tnr\n",
        "# tpr = 재현율\n",
        "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkg47NNIG-ox"
      },
      "source": [
        "def plot_roc_curve(fpr, tpr, label=None):\n",
        "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) # Not shown\n",
        "    plt.ylabel('True Positive Rate (Recall)', fontsize=16)    # Not shown\n",
        "    plt.grid(True)                                            # Not shown\n",
        "\n",
        "plot_roc_curve(fpr, tpr)\n",
        "plt.show()\n",
        "# 좋은 분류기는 점선에서 최대한 멀리 떨어져 있어야함 (왼쪽 위)\n",
        "# 점선은 완전 랜덤 분류기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq9lnDqgKX65"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(y_train_5, y_scores)\n",
        "# 완벽한 분류기는 auc=1 (accuracy 아님)\n",
        "# 완전 랜덤 분류기는 auc=0.5 (이진 분류기라서)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4qaNbNoOBiE"
      },
      "source": [
        "양성 클래스가 드물거나 거짓 음성보다 거짓 양성이 더 중요할때 PR 곡선을 사용. (정밀도/재현율)\n",
        "그렇지 않으면 ROC 사용.\n",
        "\n",
        "예를 들어 방금전 ROC 곡선이 잘 나와서 좋은 분류기라고 생각할 수 있는데 이는 음성(5아님)에 비해 양성(5)이 크게 적기 때문이다.\n",
        "이와는 다르게 PR 곡선은 분류기의 성능 개선 여지가 얼마나 되는지(오른쪽 위 모서리) 잘 보여준다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "carJHYuiNJrz"
      },
      "source": [
        "# 사이킷런은 일반적으로 decision_function() 또는 predict_proba() 메서드 둘 다 또는 둘 중 하나를 가지고있다.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest_clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5,\n",
        "                                    cv=3, method='predict_proba')\n",
        "# predict_proba() 메서느는 샘플이 행, 클래스가 열이고\n",
        "# 샘플이 주어진 클래스에 속할 확률을 담은 배열을 반환\n",
        "# (어떤 이미지가 5일 확률 70%)\n",
        "print(y_probas_forest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHOCSYpHWERe"
      },
      "source": [
        "# roc_curve()는 레이블과 점수를 기대한다. 하지만 점수 대신 클래스 확률을 전달 할 수 있다.\n",
        "y_scores_forest = y_probas_forest[:, 1] # 양성 클래스에 대한 확률을 점수로 사용\n",
        "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5, y_scores_forest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLQAiznLYnTi"
      },
      "source": [
        "plt.plot(fpr, tpr, \"b:\", linewidth=2, label=\"SGD\") \n",
        "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\") \n",
        "plt.grid(True)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aJnlQRZY2as"
      },
      "source": [
        "print(roc_auc_score(y_train_5, y_scores_forest))\n",
        "\n",
        "y_train_pred_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3)\n",
        "print(precision_score(y_train_5, y_train_pred_forest))\n",
        "print(recall_score(y_train_5, y_train_pred_forest))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8heYBUGhaouD"
      },
      "source": [
        "다중 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJInZ8lvZ9gb"
      },
      "source": [
        "# OvR : 특정 숫자 하나만 구분하는 숫자별 이진 분류기 10개(0~9)\n",
        "# OvO : 0과 1 구별, 1과 2 구별 등 각 숫자의 조합마다 이진 분류기를 훈련. (OvO 장점, 각 분류기의 훈련에 두 클래스에 해당하는 샘플만 필요)\n",
        "# SVM 빼고는 대부분 OvR 선호\n",
        "# 사이킷런은 알고리즘에 따라 자동으로 OvO 또는 OvR 실행\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_clf = SVC()\n",
        "svm_clf.fit(X_train, y_train) # y_train_5가 아니고 y_train 사용\n",
        "svm_clf.predict([some_digit])\n",
        "# 내부에서 사이킷런이 OvO 전략을 사용해 45개의 이진 분류기를 훈련시키고 각각의 결정 점수를 얻어 점수가 가장 높은 클래스 선택."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds200p-hdDte"
      },
      "source": [
        "some_digit_scores = svm_clf.decision_function([some_digit])\n",
        "print(some_digit_scores)\n",
        "\n",
        "print(np.argmax(some_digit_scores))\n",
        "\n",
        "print(svm_clf.classes_)\n",
        "print(svm_clf.classes_[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q07IFbWEeqVc"
      },
      "source": [
        "# 강제로 OvO나 OvR을 사용하는 법\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "ovr_clf = OneVsRestClassifier(SVC())\n",
        "ovr_clf.fit(X_train, y_train)\n",
        "ovr_clf.predict([some_digit])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}